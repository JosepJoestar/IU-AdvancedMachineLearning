{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# In this assignment you are going to work with Pandas\n",
    "# what is assessed is your ability to work with documentation\n",
    "# overall you need to write 5 lines of code\n",
    "# Go through the following code line by line and complete\n",
    "# the functions fill_na and embed_categories\n",
    "\n",
    "# Task Description\n",
    "# In current task you are going to do data pre-processing for KNN algorithm.\n",
    "# KNN with euclidean distance metric is designed to work only with numerical features\n",
    "# You are going to test KNN on modified Titanic dataset. You can get familiar with\n",
    "# dataset header in the file titanic_modified.csv\n",
    "\n",
    "# You are going to complete two types of pre-processing:\n",
    "# 1. Eliminating Null (N/A) values\n",
    "# 2. Mapping categorical features to binary indicator features\n",
    "\n",
    "\n",
    "def load_data(path_to_csv, has_header=True):\n",
    "    \"\"\"\n",
    "    Loads a csv file, the last column is assumed to be the output label\n",
    "    All values are interpreted as strings, empty cells interpreted as empty\n",
    "    strings\n",
    "\n",
    "    returns: X - pandas DataFrame of shape (n,m) of input features\n",
    "             Y - numpy array of output features of shape (n,)\n",
    "    \"\"\"\n",
    "    if has_header:\n",
    "        data = pd.read_csv(path_to_csv, header='infer')\n",
    "    else:\n",
    "        data = pd.read_csv(path_to_csv, header=None)\n",
    "    X = data.loc[:, data.columns[:-1]]\n",
    "    Y = data.loc[:, data.columns[-1]]\n",
    "    return X, Y.values\n",
    "\n",
    "\n",
    "def fill_na(data):\n",
    "    \"\"\"\n",
    "    Iterates over columns of DataFrame X, any N/A values replaced by the most\n",
    "    frequent element in the column\n",
    "    :param data: DataFrame with input features\n",
    "    :return: copy of the DataFrame with N/A replaced by the most frequent elements\n",
    "    \"\"\"\n",
    "    # Just to be safe, create a copy of current DataFrame\n",
    "    X = data.copy()\n",
    "    print(X.head())\n",
    "\n",
    "    # Hint: use the function mode from 'pandas.DataFrame.mode'\n",
    "    # to find a the most frequent element value of each column\n",
    "    # pay attention to keys: axis, numeric_only, dropna\n",
    "\n",
    "    mode_columns = X.mode(axis=1, numeric_only=True, dropna=True)\n",
    "    print(mode_columns)\n",
    "\n",
    "    for col_name in X.columns:  # current column name\n",
    "        is_null = X[col_name].isnull()  # check for N/A values\n",
    "        if is_null.any():\n",
    "            ### Find the most frequent element value in the current column\n",
    "            ### Hint: the value of moda_columns can be obtained as\n",
    "            ### moda_columns[col_name]\n",
    "\n",
    "            None  # <<-- write code here\n",
    "\n",
    "            ### Replace N/A entries with most_common value\n",
    "            ### Hint: slice DataFrame with X.loc[is_null, col_name]\n",
    "\n",
    "            None  # <<-- write code here\n",
    "\n",
    "    ### Please visually check the first 10 rows of data\n",
    "    ### Hint: try a comand from pandas 'DataFrame[column_name].values[0]'\n",
    "    # print(X.head(10))\n",
    "    return X\n",
    "\n",
    "\n",
    "def one_hot(data, dummy_columns=[]):\n",
    "    \"\"\"\n",
    "    Replaces columns with categorical features by binary feature indicator columns\n",
    "    >> print(X.info())\n",
    "    You'll see something like that:\n",
    "    Data columns (total 6 columns):\n",
    "    Pclass      891 non-null int64\n",
    "    Sex         891 non-null object\n",
    "    Age         891 non-null float64\n",
    "    SibSp       891 non-null int64\n",
    "    Parch       891 non-null int64\n",
    "    Embarked    891 non-null object\n",
    "    dtypes: float64(1), int64(3), object(2)\n",
    "\n",
    "    columns ['Sex', 'Embarked'] are cathegorical\n",
    "    column ['Pclass'] is cathegorical as well. This is a passenger ticket class\n",
    "\n",
    "    INPUT: \n",
    "    DataFrame with input features: cathegorical and numeric\n",
    "    dummy_columns = column names which need to be transformed to dummies\n",
    "\n",
    "    OUTPUT: \n",
    "    DataFrame with numeric feature indicators \n",
    "    \"\"\"\n",
    "    X = data.copy()\n",
    "    # print(X.info())\n",
    "\n",
    "    for col_name in dummy_columns:\n",
    "        ### create a new DataFrame which represents a categorical column\n",
    "        ### Hint: use a pd.get_dummies(data=None, prefix=None)\n",
    "\n",
    "        None  # <<-- write code here\n",
    "\n",
    "        ### drop a categorical column from X\n",
    "        ### Hint: use DataFrame.drop(labels=[None], inplaec=None, axis=None)\n",
    "\n",
    "        None  # <<-- write code here\n",
    "\n",
    "        ### join dummy columns with DataFrame\n",
    "        ### Hint: use DataFrame.join([None])\n",
    "\n",
    "        None  # <<-- write code here\n",
    "    return X.values\n",
    "\n",
    "\n",
    "def k_fold_validation(X, Y):\n",
    "    kf = KFold(n_splits=50)\n",
    "    fold_score = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        knn = KNeighborsClassifier()\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        fold_score.append(f1_score(y_test, y_pred))\n",
    "    return np.mean(fold_score)\n",
    "\n",
    "\n",
    "def performance_test(X, Y):\n",
    "    # Test the performance with one hot categorical feature embeddings\n",
    "    s1 = k_fold_validation(X, Y)\n",
    "    print(\"Score for original features: \", s1)\n",
    "\n",
    "    # After checking the performance of this classification procedure\n",
    "    # apply a dimensionality reduction technique (PCA). It several purposes:\n",
    "    # 1. Implicit data normalization (PCA pre-processing)\n",
    "    # 2. Feature orthogonalization\n",
    "    # 3. Dimensionality reduction\n",
    "\n",
    "    # Apply Principal Component Analysis\n",
    "    pca_components = X.shape[1] - 2  # reduce features dimension by 2\n",
    "    pca = PCA(n_components=pca_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    # Test the performance with transformed features\n",
    "    s2 = k_fold_validation(X_pca, Y)\n",
    "    print(\"Score for transformed features: \", s2)\n",
    "    # You should observe gain around 1-3%\n",
    "    print(\"Gain: \", s2 - s1)\n",
    "\n",
    "\n",
    "X, Y = load_data(\"titanic_modified.csv\")\n",
    "X = fill_na(X)\n",
    "\n",
    "X2 = one_hot(X, ['Sex', 'Embarked'])\n",
    "X3 = one_hot(X, ['Sex', 'Embarked', 'Pclass'])\n",
    "\n",
    "performance_test(X2, Y)\n",
    "performance_test(X3, Y)\n",
    "\n",
    "'''\n",
    "MANDATORY! \n",
    "Write your observation and conclusion in the comment below observation:\n",
    "\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
