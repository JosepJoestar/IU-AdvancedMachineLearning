{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Odd-Even classification with TensorFlow (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Let's load the dataset using the Keras API implementation included in TensorFlow.\n",
    "\n",
    "As we only want to classify the images between **odd** and **even** numbers, we will map labels to *1* if odd or *0* if even."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Keep original test numbers for displaying\n",
    "y_numbers = y_test\n",
    "\n",
    "# Set Even or Odd labels for each sample\n",
    "y_train = np.array(list(map(lambda x: [1, 0] if x%2 else [0, 1], y_train)), dtype=np.float32)\n",
    "y_test = np.array(list(map(lambda x: [1, 0] if x%2 else [0, 1], y_test)), dtype=np.float32)\n",
    "\n",
    "# Normalize images dividing by max pixel value (255)\n",
    "x_train = (x_train / 255.0).astype(np.float32)\n",
    "x_test = (x_test / 255.0).astype(np.float32)\n",
    "\n",
    "# Reshape to TF API (#img, rows, cols, channels)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqk5XzLt61LE"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EKJgxT9g61LF"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 120\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVAWymGh61LS"
   },
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder for input data formatted as N*784 tensors (image_size = 28*28 = 784)\n",
    "x = tf.placeholder(name='x', dtype=tf.float32, shape=(None, 784))\n",
    "# Input data in image format for Convolutional Layers\n",
    "x_image = tf.reshape(x, shape=(-1, 28, 28, 1))\n",
    "\n",
    "# Placeholder for labels formatted as N*2 tensors (2 classes -> odd | even)\n",
    "y_true = tf.placeholder(name=\"y_true\", dtype=tf.float32, shape=(None, 2))\n",
    "# To calculate true class\n",
    "y_true_class = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data into a Dataset placeholder\n",
    "features_placeholder = tf.placeholder(x_train.dtype, x_train.shape)\n",
    "labels_placeholder = tf.placeholder(y_train.dtype, y_train.shape)\n",
    "\n",
    "# Create TF.Dataset from the data, making it repeatable, grouping by batch size and shuffling it in each epoch\n",
    "training_set = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\n",
    "training_set = training_set.batch(BATCH_SIZE)\n",
    "training_set = training_set.repeat(EPOCHS)\n",
    "training_set = training_set.shuffle(len(x_train))\n",
    "\n",
    "# Iterator to deal with the dataset in the training loop\n",
    "training_set_iterator = training_set.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ssn0x0rC61Lg"
   },
   "source": [
    "### Neural Network architecture\n",
    "\n",
    "We will use the classical architecture for a CNN (Convolution + Pooling > Convolution + Pooling > Flatten > Dense > Dense)\n",
    "\n",
    "Instead of the common Convolution > ReLU > Pooling, we can apply the ReLU after Pooling step beacuse ReLU(MaxPooling(x)) == MaxPooling(ReLU(x)) and it will be more efficient, as the tensor size will be 75% smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1st Convolutional Layer 32x5x5 Kernel\n",
    "conv1 = tf.layers.conv2d(x_image,\n",
    "                         filters=32,\n",
    "                         kernel_size=(5, 5),\n",
    "                         padding='same')\n",
    "\n",
    "# Apply MaxPooling 2x2\n",
    "pool1 = tf.layers.max_pooling2d(conv1,\n",
    "                                pool_size=(2, 2),\n",
    "                                strides=2)\n",
    "\n",
    "# Apply ReLU activation function\n",
    "relu1 = tf.nn.relu(pool1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2nd Convolutional Layer 64x5x5 Kernel\n",
    "conv2 = tf.layers.conv2d(relu1,\n",
    "                         filters=64,\n",
    "                         kernel_size=(5, 5),\n",
    "                         padding='same')\n",
    "\n",
    "# Apply MaxPooling 2x2\n",
    "pool2 = tf.layers.max_pooling2d(conv2,\n",
    "                                pool_size=(2, 2),\n",
    "                                strides=2)\n",
    "\n",
    "# Apply ReLu activation function\n",
    "relu2 = tf.nn.relu(pool2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply Dropout p=0.25\n",
    "dropout1 = tf.layers.dropout(relu2, rate=0.25)\n",
    "\n",
    "# Flatten data into (-1, 7*7*64 tensor)\n",
    "flatten = tf.reshape(dropout1, shape=(-1, 7*7*64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dense Layer 1 with 100 neurons\n",
    "dense1 = tf.layers.dense(flatten, units=100, activation=tf.nn.relu)\n",
    "\n",
    "# Apply Dropout p=0.5\n",
    "dropout2 = tf.layers.dropout(dense1, rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dense Layer 2 with 2 neurons (our final output)\n",
    "dense2 = tf.layers.dense(dense1, units=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = tf.nn.softmax(dense2)\n",
    "\n",
    "# Predicted class\n",
    "y_pred_class = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-Entropy as loss function\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=dense2, labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use ADAM optimizer to minimize the loss function defined previously\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_class, y_true_class)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Vepqscnk61L_"
   },
   "outputs": [],
   "source": [
    "def train(session):\n",
    "    next_element = training_set_iterator.get_next()\n",
    "    \n",
    "    num_iterations = EPOCHS * (len(x_train) // BATCH_SIZE)\n",
    "    for it in range(1, num_iterations + 1):\n",
    "        x_batch, y_true_batch = session.run(next_element)\n",
    "\n",
    "        feed_dict_train = { x_image: x_batch,\n",
    "                            y_true: y_true_batch }\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        \n",
    "        if it % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            msg = 'Iteration: {:>4}, Training Accuracy: {:>6.2%}'\n",
    "            print(msg.format(it, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "b6S84B1e61MH"
   },
   "outputs": [],
   "source": [
    "def test(session):\n",
    "    predictions = []\n",
    "    correct = 0\n",
    "    for image, label in zip(x_test, y_test):\n",
    "        feed_dict = { x_image: image.reshape(-1, 28, 28, 1),\n",
    "                      y_true: label.reshape(-1, 2)}\n",
    "                      \n",
    "        prediction_class = session.run(y_pred_class, feed_dict=feed_dict)\n",
    "        predictions.append(prediction_class[0])\n",
    "        \n",
    "        if (prediction_class[0] == np.argmax(label)):\n",
    "            correct += 1\n",
    "            \n",
    "    acc = float(correct) / len(x_test)\n",
    "    msg = '\\nAccuracy on Test-Set: {0:.2%} ({1} / {2})'\n",
    "    print(msg.format(acc, correct, len(x_test)))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_missclasifications(preds):\n",
    "    count = 0\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, pred in enumerate(preds):\n",
    "        if pred != np.argmax(y_test[i]):\n",
    "            msg = '{} ({})'\n",
    "            msg = msg.format('Even' if preds[i] else 'Odd', str(y_numbers[i]))\n",
    "        \n",
    "            plt.subplot(2, 5, count + 1)\n",
    "            plt.title(msg)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(x_test[i].reshape(28, 28), cmap=cm.binary)\n",
    "            count += 1\n",
    "            if count == 10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CNN in a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uj88pBRy61MM",
    "outputId": "0c068a0a-4384-4fdf-b988-61fd9f2ef17b"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(training_set_iterator.initializer, feed_dict={ features_placeholder: x_train,\n",
    "                                                            labels_placeholder: y_train })\n",
    "    \n",
    "    train(sess)\n",
    "    predictions = test(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some missclassification examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missclasifications(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
